{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 16:24:06 | INFO | fairseq.file_utils | loading archive file /home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer\n",
      "2024-04-16 16:24:06 | INFO | fairseq.file_utils | loading archive file /home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:425: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/compose.py:56: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/fairseq/models/fairseq_model.py:267: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  x = hub_utils.from_pretrained(\n",
      "2024-04-16 16:43:01 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2024-04-16 16:43:01 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2024-04-16 16:43:05 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0253:58342', 'distributed_port': 58342, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 5120, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5120, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', seed=2, data='/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer', source_lang='en', target_lang='fr', max_source_positions=1024, max_target_positions=1024, skip_invalid_size_inputs_valid_test=False, max_tokens=5120, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, sample_without_replacement=0, distributed_world_size=128, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0253:58342', distributed_port=58342, device_id=0, arch='transformer_vaswani_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=80000, clip_norm=0.0, sentence_avg=False, update_freq=[1.0], fp16=True, optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', restore_file='checkpoint_last.pt', save_interval=1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, dropout=0.1, attention_dropout=0.0, relu_dropout=0.0, encoder_normalize_before=False, encoder_learned_pos=False, decoder_learned_pos=False, decoder_normalize_before=False, share_decoder_input_output_embed=True, share_all_embeddings=True, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_attention_heads=16, bpe='subword_nmt', bpe_codes='/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer/bpecodes', task='translation', stop_min_lr=1e-09, _name='transformer_vaswani_wmt_en_de_big', encoder_embed_path=None, decoder_embed_path=None, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer/bpecodes', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Generator loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "path_to_your_pretrained_model = '/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer'\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "generator_pt = TransformerModel.from_pretrained(\n",
    "model_name_or_path=path_to_your_pretrained_model,\n",
    "checkpoint_file='model.pt',\n",
    "bpe='subword_nmt',\n",
    "# data_name_or_path='/u/prattisr/phase-2/all_repos/Adversarial_NMT/neural-machine-translation-using-gan-master/data-bin/wmt14_en_fr_raw_sm/50kLines',\n",
    "data_name_or_path='/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer',\n",
    "bpe_codes = '/home/paperspace/google_drive_v1/Research_Thesis/2024/Adversarial_NMT_th/pretrained_models/wmt14.en-fr.joined-dict.transformer/bpecodes'\n",
    ")\n",
    "print(\"Pretrained Generator loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fairseq.hub_utils.GeneratorHubInterface"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generator_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_pt.eval()\n",
    "sentence_to_translate = \"Good Morning, I am going to a picnic tomorrow\"\n",
    "# translated_sentences = generator_pt.translate([\"Good Morning, I am going to a picnic tomorrow\",\"Good Afternoon\"])\n",
    "translated_sentences = generator_pt.translate(sentence_to_translate)\n",
    "# translated_sentences = generator_pt.translate(['Je suis sriram', 'Bon apr√®s @-@ midi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bon matin , je vais faire un pique @-@ nique demain .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_translate_toks = generator_pt.tokenize(sentence_to_translate)\n",
    "sentence_to_translate_bpe = generator_pt.apply_bpe(sentence_to_translate_toks)\n",
    "sentence_to_translate_bnrz = generator_pt.binarize(sentence_to_translate_bpe)\n",
    "\n",
    "translated_sentences_using_generate = generator_pt.generate(sentence_to_translate_bnrz, beam=5, sampling=True, sampling_topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': tensor([ 9804,   391,     4, 11548,     4,   471, 13772,   184,    33, 24715,\n",
       "             17, 35429,     2]),\n",
       "  'score': tensor(-0.5770),\n",
       "  'attention': tensor([[4.9452e-01, 2.5984e-02, 1.1782e-01, 1.0228e-01, 2.8326e-02, 8.5267e-02,\n",
       "           8.3771e-03, 5.0618e-03, 3.4623e-03, 8.7738e-03, 8.2156e-04, 5.5009e-04,\n",
       "           3.4776e-02],\n",
       "          [2.1300e-01, 1.4918e-01, 4.2657e-01, 6.8923e-02, 6.1092e-02, 8.3069e-02,\n",
       "           1.0876e-02, 6.8625e-03, 4.8859e-03, 3.6718e-03, 7.6182e-03, 2.4095e-03,\n",
       "           4.1339e-02],\n",
       "          [6.7006e-03, 1.3594e-02, 7.3953e-02, 2.1945e-03, 2.7774e-03, 3.4765e-03,\n",
       "           2.0275e-03, 5.9349e-04, 4.6940e-04, 3.2411e-03, 1.1718e-02, 4.8259e-03,\n",
       "           2.6926e-03],\n",
       "          [1.1468e-02, 5.9789e-03, 6.1731e-02, 1.9828e-03, 1.6616e-03, 1.5582e-03,\n",
       "           1.2446e-03, 1.2807e-03, 8.3491e-04, 1.0579e-03, 4.3197e-03, 2.3071e-03,\n",
       "           2.3031e-03],\n",
       "          [1.5785e-02, 5.5890e-03, 1.4403e-02, 8.2340e-03, 7.9631e-03, 6.1776e-03,\n",
       "           5.5518e-03, 4.1026e-03, 1.4576e-02, 1.5530e-03, 4.5018e-03, 3.2129e-03,\n",
       "           6.7994e-03],\n",
       "          [1.7507e-02, 8.9580e-03, 6.0052e-03, 4.8391e-02, 1.0376e-01, 6.9804e-02,\n",
       "           1.5341e-02, 2.0594e-02, 1.7130e-02, 3.8096e-03, 2.9733e-03, 1.0807e-03,\n",
       "           1.2778e-02],\n",
       "          [7.1104e-03, 1.9473e-03, 1.2723e-03, 2.4874e-02, 3.3783e-02, 2.9038e-02,\n",
       "           3.2005e-02, 6.2606e-03, 4.3090e-03, 1.3220e-03, 9.7481e-04, 2.4712e-04,\n",
       "           4.1332e-03],\n",
       "          [6.8949e-03, 1.9310e-03, 1.0688e-03, 3.9204e-02, 8.0575e-02, 7.0729e-02,\n",
       "           1.2969e-01, 1.9317e-02, 4.7092e-03, 1.8119e-03, 1.0530e-03, 3.3923e-04,\n",
       "           3.8464e-03],\n",
       "          [4.3452e-03, 3.9618e-04, 6.1907e-04, 1.3932e-02, 4.1178e-02, 3.7711e-02,\n",
       "           9.6978e-02, 4.7279e-02, 9.7814e-03, 4.6797e-03, 2.0221e-03, 9.3256e-04,\n",
       "           7.3301e-03],\n",
       "          [2.5610e-03, 3.0437e-04, 4.9595e-04, 7.8539e-03, 2.1054e-02, 1.8220e-02,\n",
       "           7.7381e-03, 2.2172e-02, 2.7235e-02, 8.1564e-03, 3.2817e-03, 1.1809e-03,\n",
       "           6.4816e-03],\n",
       "          [1.2490e-02, 5.8952e-03, 2.5250e-03, 4.1282e-02, 1.6353e-01, 1.5761e-01,\n",
       "           2.7632e-01, 3.8985e-01, 1.5627e-01, 4.8658e-01, 3.8582e-02, 1.5673e-02,\n",
       "           2.8120e-02],\n",
       "          [6.2965e-03, 2.4159e-03, 3.1994e-03, 9.8439e-03, 4.5678e-02, 3.6751e-02,\n",
       "           1.0965e-01, 1.9164e-01, 7.4367e-02, 1.8930e-01, 2.1785e-01, 1.3573e-01,\n",
       "           1.6520e-02],\n",
       "          [5.2392e-02, 2.6608e-02, 5.6384e-03, 4.1731e-01, 6.5586e-02, 1.1789e-01,\n",
       "           2.4526e-02, 5.4493e-02, 1.0737e-01, 2.2131e-02, 2.2896e-02, 3.5656e-03,\n",
       "           1.3558e-01],\n",
       "          [1.4893e-01, 7.5122e-01, 2.8470e-01, 2.1369e-01, 3.4304e-01, 2.8270e-01,\n",
       "           2.7968e-01, 2.3049e-01, 5.7460e-01, 2.6391e-01, 6.8139e-01, 8.2794e-01,\n",
       "           6.9730e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-0.9569, -0.1617, -1.3670, -1.3469, -0.7934, -0.2061, -0.3429, -0.8463,\n",
       "          -0.1570, -0.1277, -0.1216, -0.0506, -1.0229])},\n",
       " {'tokens': tensor([ 9804,   391,    16,   173,     4, 11548,     4,   471, 13772,   184,\n",
       "             33, 24715,    17, 35429,     7,     2]),\n",
       "  'score': tensor(-0.5930),\n",
       "  'attention': tensor([[4.9452e-01, 2.5984e-02, 1.1782e-01, 2.2427e-01, 6.1300e-02, 3.7056e-02,\n",
       "           9.7818e-03, 2.1638e-02, 4.6338e-03, 3.4064e-03, 2.8894e-03, 7.5879e-03,\n",
       "           7.2845e-04, 4.7471e-04, 1.7726e-02, 3.2793e-02],\n",
       "          [2.1300e-01, 1.4918e-01, 4.2657e-01, 2.6486e-01, 1.3356e-01, 2.0533e-02,\n",
       "           1.6008e-02, 1.7002e-02, 5.7308e-03, 4.7128e-03, 4.0647e-03, 3.0632e-03,\n",
       "           6.6408e-03, 2.0188e-03, 2.0701e-02, 2.1882e-02],\n",
       "          [6.7006e-03, 1.3594e-02, 7.3953e-02, 2.1870e-02, 7.1546e-03, 8.4012e-04,\n",
       "           1.0892e-03, 1.1244e-03, 1.1165e-03, 4.0900e-04, 4.0220e-04, 2.6992e-03,\n",
       "           1.0871e-02, 4.2000e-03, 1.4843e-03, 2.3753e-03],\n",
       "          [1.1468e-02, 5.9789e-03, 6.1731e-02, 4.1392e-02, 7.2530e-03, 5.8079e-04,\n",
       "           5.7874e-04, 4.3766e-04, 6.4070e-04, 7.2260e-04, 6.6873e-04, 8.2884e-04,\n",
       "           3.7195e-03, 1.9574e-03, 1.2795e-03, 1.4458e-03],\n",
       "          [1.5785e-02, 5.5890e-03, 1.4403e-02, 1.7385e-02, 2.6247e-02, 5.3051e-03,\n",
       "           4.9850e-03, 4.1419e-03, 3.9486e-03, 3.2141e-03, 1.4274e-02, 1.4337e-03,\n",
       "           4.0708e-03, 3.2441e-03, 5.0423e-03, 1.0905e-02],\n",
       "          [1.7507e-02, 8.9580e-03, 6.0052e-03, 9.1000e-03, 6.7429e-02, 6.6657e-02,\n",
       "           9.6376e-02, 8.0693e-02, 1.4786e-02, 2.0008e-02, 1.8349e-02, 3.8394e-03,\n",
       "           2.7070e-03, 1.0727e-03, 1.2737e-02, 1.5511e-02],\n",
       "          [7.1104e-03, 1.9473e-03, 1.2723e-03, 9.8049e-04, 1.4408e-02, 3.3217e-02,\n",
       "           3.6739e-02, 3.4006e-02, 3.1072e-02, 6.5388e-03, 4.3547e-03, 1.3773e-03,\n",
       "           9.3635e-04, 2.4880e-04, 4.1701e-03, 4.6471e-03],\n",
       "          [6.8949e-03, 1.9310e-03, 1.0688e-03, 1.3952e-03, 1.0235e-02, 5.4362e-02,\n",
       "           9.9740e-02, 8.8957e-02, 1.3102e-01, 2.1106e-02, 4.8345e-03, 1.8795e-03,\n",
       "           1.0516e-03, 3.4511e-04, 4.1233e-03, 4.5326e-03],\n",
       "          [4.3452e-03, 3.9618e-04, 6.1907e-04, 8.3980e-04, 5.8609e-03, 2.1920e-02,\n",
       "           4.9901e-02, 5.2771e-02, 9.8675e-02, 4.8289e-02, 9.9549e-03, 4.8066e-03,\n",
       "           1.9919e-03, 9.1963e-04, 8.3761e-03, 2.9821e-03],\n",
       "          [2.5610e-03, 3.0437e-04, 4.9595e-04, 2.3865e-03, 2.4017e-03, 1.1626e-02,\n",
       "           2.6873e-02, 2.4521e-02, 8.8594e-03, 2.2016e-02, 2.7488e-02, 8.8608e-03,\n",
       "           3.1331e-03, 1.1509e-03, 8.1033e-03, 3.1262e-03],\n",
       "          [1.2490e-02, 5.8952e-03, 2.5250e-03, 3.2356e-03, 1.2262e-02, 7.4054e-02,\n",
       "           1.9337e-01, 1.9971e-01, 2.8362e-01, 3.8402e-01, 1.6022e-01, 4.8539e-01,\n",
       "           3.9346e-02, 1.5509e-02, 3.3212e-02, 9.6052e-03],\n",
       "          [6.2965e-03, 2.4159e-03, 3.1994e-03, 2.5585e-03, 3.6606e-03, 1.4835e-02,\n",
       "           5.9049e-02, 4.7501e-02, 1.1893e-01, 1.9298e-01, 7.6351e-02, 1.8848e-01,\n",
       "           2.2724e-01, 1.3566e-01, 1.9629e-02, 4.2680e-03],\n",
       "          [5.2392e-02, 2.6608e-02, 5.6384e-03, 3.7852e-03, 8.4266e-02, 4.4486e-01,\n",
       "           7.0072e-02, 1.1362e-01, 2.7599e-02, 6.0244e-02, 1.0866e-01, 2.4138e-02,\n",
       "           2.4043e-02, 3.5086e-03, 1.6752e-01, 3.9772e-02],\n",
       "          [1.4893e-01, 7.5122e-01, 2.8470e-01, 4.0594e-01, 5.6396e-01, 2.1416e-01,\n",
       "           3.3543e-01, 3.1388e-01, 2.6936e-01, 2.3234e-01, 5.6749e-01, 2.6561e-01,\n",
       "           6.7352e-01, 8.2969e-01, 6.9589e-01, 8.4615e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-0.9569, -0.1617, -2.1894, -0.2832, -0.5154, -1.5030, -1.0885, -0.1961,\n",
       "          -0.3272, -0.8740, -0.1678, -0.1266, -0.1252, -0.0528, -0.8152, -0.1055])},\n",
       " {'tokens': tensor([  255,  7243, 33597,   342,     4, 11548,   471, 13772, 24715,    17,\n",
       "           2511,  6062,     2]),\n",
       "  'score': tensor(-0.7311),\n",
       "  'attention': tensor([[4.9452e-01, 1.3585e-01, 4.4123e-02, 1.2497e-02, 2.9693e-02, 1.6742e-02,\n",
       "           6.4132e-03, 3.2266e-03, 2.4082e-03, 6.4964e-04, 5.5629e-04, 2.3096e-03,\n",
       "           1.9518e-02],\n",
       "          [2.1300e-01, 1.0203e-01, 3.4556e-01, 1.8764e-02, 3.6897e-02, 7.9515e-03,\n",
       "           8.3280e-03, 3.2478e-03, 2.6372e-03, 4.4293e-03, 1.8642e-03, 2.1742e-03,\n",
       "           1.6817e-02],\n",
       "          [6.7006e-03, 1.4069e-02, 4.7352e-02, 9.6709e-03, 3.3410e-03, 4.1474e-04,\n",
       "           7.5571e-04, 8.4526e-04, 2.8618e-04, 8.3541e-03, 3.1534e-03, 4.0001e-03,\n",
       "           1.8327e-03],\n",
       "          [1.1468e-02, 9.0962e-03, 4.7761e-02, 3.6612e-02, 7.4676e-03, 2.5475e-04,\n",
       "           3.9529e-04, 4.4294e-04, 5.3031e-04, 1.9742e-03, 1.4852e-03, 4.3964e-03,\n",
       "           2.0791e-03],\n",
       "          [1.5785e-02, 1.1480e-02, 1.1597e-02, 4.6172e-02, 3.1943e-02, 3.4167e-03,\n",
       "           4.0220e-03, 3.1314e-03, 2.5396e-03, 3.8614e-03, 3.0320e-03, 3.0717e-03,\n",
       "           7.1614e-03],\n",
       "          [1.7507e-02, 4.9424e-03, 3.4959e-03, 4.9837e-03, 9.4726e-02, 7.7688e-02,\n",
       "           1.0192e-01, 1.6006e-02, 1.9243e-02, 2.9924e-03, 1.7322e-03, 6.0436e-03,\n",
       "           1.5599e-02],\n",
       "          [7.1104e-03, 2.1022e-03, 1.2851e-03, 1.7082e-03, 1.3429e-02, 3.2266e-02,\n",
       "           3.2165e-02, 3.1169e-02, 5.7192e-03, 6.8131e-04, 2.8157e-04, 1.1455e-03,\n",
       "           5.4016e-03],\n",
       "          [6.8949e-03, 3.2747e-03, 2.2398e-03, 8.8357e-04, 9.9391e-03, 6.3334e-02,\n",
       "           8.6630e-02, 1.4277e-01, 2.0394e-02, 1.0376e-03, 4.7074e-04, 1.6685e-03,\n",
       "           4.9515e-03],\n",
       "          [4.3452e-03, 8.7168e-04, 2.1475e-03, 1.0176e-03, 8.2549e-03, 3.1301e-02,\n",
       "           5.0311e-02, 9.9352e-02, 4.5420e-02, 1.9549e-03, 1.3160e-03, 2.3691e-03,\n",
       "           8.2044e-03],\n",
       "          [2.5610e-03, 1.9285e-03, 5.5399e-04, 1.1661e-03, 2.9941e-03, 1.6388e-02,\n",
       "           2.8564e-02, 9.3760e-03, 2.4587e-02, 2.4072e-03, 1.2974e-03, 2.3617e-03,\n",
       "           1.0838e-02],\n",
       "          [1.2490e-02, 1.9890e-03, 6.9380e-03, 1.1110e-03, 8.3135e-03, 1.5091e-01,\n",
       "           2.1451e-01, 2.9324e-01, 4.0789e-01, 2.5622e-02, 8.9431e-03, 7.2472e-03,\n",
       "           1.9608e-02],\n",
       "          [6.2965e-03, 1.3842e-03, 1.6471e-02, 3.5582e-03, 4.5438e-03, 3.0249e-02,\n",
       "           6.6143e-02, 1.2819e-01, 2.0219e-01, 1.4877e-01, 9.0957e-02, 3.7003e-02,\n",
       "           1.4134e-02],\n",
       "          [5.2392e-02, 3.5404e-03, 1.4162e-02, 5.5330e-03, 1.1304e-01, 3.5947e-01,\n",
       "           4.7788e-02, 2.1750e-02, 4.1887e-02, 1.7978e-02, 5.3857e-03, 1.4980e-02,\n",
       "           6.0272e-02],\n",
       "          [1.4893e-01, 7.0745e-01, 4.5632e-01, 8.5632e-01, 6.3542e-01, 2.0962e-01,\n",
       "           3.5205e-01, 2.4726e-01, 2.2427e-01, 7.7928e-01, 8.7953e-01, 9.1123e-01,\n",
       "           8.1358e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-2.5025, -0.0329, -1.3654, -0.0914, -0.1681, -1.8778, -0.7552, -0.2605,\n",
       "          -1.3514, -0.1690, -0.2029, -0.0859, -0.6414])},\n",
       " {'tokens': tensor([  330,  9599,     4,   471, 13772,   613,  1766,    16,  2100, 24715,\n",
       "             17,  2511,    30, 11548,     7,     2]),\n",
       "  'score': tensor(-1.4728),\n",
       "  'attention': tensor([[4.9452e-01, 3.7554e-01, 2.9943e-01, 2.1153e-01, 3.7620e-02, 1.3655e-02,\n",
       "           1.0591e-02, 9.2783e-03, 1.1494e-02, 2.9785e-02, 1.2891e-03, 5.1925e-04,\n",
       "           2.6793e-03, 1.6594e-02, 5.3180e-02, 6.9167e-02],\n",
       "          [2.1300e-01, 2.0713e-01, 1.3619e-01, 1.0523e-01, 3.6103e-02, 1.3860e-02,\n",
       "           1.2281e-02, 9.4122e-03, 8.9538e-03, 6.8628e-03, 1.0576e-02, 2.4426e-03,\n",
       "           2.7903e-03, 1.0862e-02, 7.2372e-02, 4.4577e-02],\n",
       "          [6.7006e-03, 1.1097e-02, 4.6503e-03, 3.3071e-03, 4.1161e-03, 6.8116e-04,\n",
       "           2.5890e-03, 2.5849e-04, 6.2511e-04, 2.5306e-03, 1.6034e-02, 5.9949e-03,\n",
       "           3.8503e-03, 4.3977e-04, 4.4042e-03, 4.9723e-03],\n",
       "          [1.1468e-02, 1.3790e-02, 1.6560e-02, 3.7970e-03, 4.1354e-03, 2.2762e-03,\n",
       "           1.2842e-03, 7.5745e-04, 1.0691e-03, 1.3514e-03, 4.8707e-03, 2.1308e-03,\n",
       "           5.6880e-03, 5.8239e-04, 3.8652e-03, 3.6958e-03],\n",
       "          [1.5785e-02, 1.0376e-02, 2.0598e-02, 1.4755e-02, 1.4317e-02, 8.9064e-03,\n",
       "           7.5483e-03, 5.9920e-03, 5.1063e-03, 2.9464e-03, 5.1026e-03, 2.9868e-03,\n",
       "           4.6222e-03, 4.4139e-03, 1.1597e-02, 1.4984e-02],\n",
       "          [1.7507e-02, 9.5585e-03, 6.1962e-02, 7.6546e-02, 2.5511e-02, 2.6947e-02,\n",
       "           1.3270e-02, 1.1245e-02, 2.6872e-02, 7.1430e-03, 3.0213e-03, 9.7909e-04,\n",
       "           5.7564e-03, 1.3030e-02, 1.1898e-02, 1.4489e-02],\n",
       "          [7.1104e-03, 1.4554e-03, 1.0230e-02, 3.9487e-02, 4.5566e-02, 8.7089e-03,\n",
       "           1.3913e-02, 4.0823e-03, 4.7661e-03, 5.3995e-03, 1.2087e-03, 2.1235e-04,\n",
       "           1.1483e-03, 5.3801e-03, 5.1523e-03, 4.4333e-03],\n",
       "          [6.8949e-03, 1.6040e-03, 8.7721e-03, 6.0788e-02, 1.2222e-01, 2.4009e-02,\n",
       "           1.7281e-02, 4.1051e-03, 9.5227e-03, 6.7331e-03, 1.1666e-03, 2.2215e-04,\n",
       "           7.8600e-04, 5.9918e-03, 4.1103e-03, 3.8829e-03],\n",
       "          [4.3452e-03, 1.3551e-03, 4.3735e-03, 3.0054e-02, 8.8164e-02, 4.6668e-02,\n",
       "           8.2891e-02, 1.0335e-02, 1.8871e-02, 1.3138e-02, 2.4523e-03, 7.1571e-04,\n",
       "           1.2279e-03, 9.2084e-03, 8.0291e-03, 2.5238e-03],\n",
       "          [2.5610e-03, 1.9818e-03, 4.5965e-03, 1.4230e-02, 6.8634e-03, 1.9224e-02,\n",
       "           1.6402e-02, 2.4714e-02, 5.4510e-02, 1.5025e-02, 3.5624e-03, 1.0336e-03,\n",
       "           1.7147e-03, 7.2362e-03, 5.2394e-03, 2.3470e-03],\n",
       "          [1.2490e-02, 5.8837e-03, 1.0906e-02, 6.3146e-02, 2.3591e-01, 3.7683e-01,\n",
       "           1.5395e-01, 1.4485e-01, 1.9095e-01, 4.1684e-01, 5.1315e-02, 1.0143e-02,\n",
       "           5.2155e-03, 4.3009e-02, 1.9825e-02, 8.7595e-03],\n",
       "          [6.2965e-03, 6.3901e-03, 7.5919e-03, 2.0596e-02, 8.4834e-02, 1.6582e-01,\n",
       "           7.0561e-02, 7.0120e-02, 1.4321e-01, 2.3240e-01, 2.2625e-01, 1.1795e-01,\n",
       "           2.9042e-02, 2.3409e-02, 1.0335e-02, 4.1289e-03],\n",
       "          [5.2392e-02, 6.9642e-03, 6.7493e-02, 1.3669e-01, 3.8218e-02, 1.1355e-01,\n",
       "           2.5946e-02, 3.7382e-01, 6.9286e-02, 1.5444e-02, 2.2190e-02, 2.7216e-03,\n",
       "           1.2591e-02, 5.1361e-01, 3.3335e-02, 2.5348e-02],\n",
       "          [1.4893e-01, 3.4687e-01, 3.4665e-01, 2.1985e-01, 2.5642e-01, 1.7886e-01,\n",
       "           5.7149e-01, 3.3104e-01, 4.5476e-01, 2.4440e-01, 6.5096e-01, 8.5195e-01,\n",
       "           9.2289e-01, 3.4623e-01, 7.5666e-01, 7.9669e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-5.1777, -3.7706, -0.2636, -0.4439, -0.6683, -2.7314, -0.2357, -0.3727,\n",
       "          -3.5801, -0.2437, -0.1322, -4.0542, -0.3719, -0.7036, -0.7097, -0.1054])},\n",
       " {'tokens': tensor([15671,  9255,     4,   471,  3740,   109, 13772, 19481,    11, 10680,\n",
       "           9255,     7,     2]),\n",
       "  'score': tensor(-2.1489),\n",
       "  'attention': tensor([[4.9452e-01, 5.6259e-02, 1.9477e-02, 1.9461e-02, 7.3392e-03, 6.6423e-03,\n",
       "           4.6061e-03, 1.0623e-02, 1.6758e-02, 1.7165e-02, 1.4411e-02, 1.6709e-02,\n",
       "           4.6999e-02],\n",
       "          [2.1300e-01, 3.5108e-01, 2.7485e-02, 1.1486e-02, 8.1609e-03, 3.8599e-03,\n",
       "           4.1037e-03, 6.4435e-03, 4.2753e-02, 1.7727e-02, 4.4695e-02, 2.6083e-02,\n",
       "           2.8783e-02],\n",
       "          [6.7006e-03, 5.5886e-02, 2.5912e-03, 5.1184e-04, 1.1061e-03, 1.3246e-03,\n",
       "           9.0015e-04, 2.2280e-04, 1.7765e-03, 1.3839e-03, 2.4601e-03, 1.4648e-03,\n",
       "           3.0954e-03],\n",
       "          [1.1468e-02, 4.1106e-02, 3.6995e-03, 2.9827e-04, 8.1164e-04, 1.0841e-03,\n",
       "           7.3864e-04, 3.8588e-04, 1.2826e-03, 9.4682e-04, 1.6214e-03, 1.0989e-03,\n",
       "           1.5759e-03],\n",
       "          [1.5785e-02, 1.1369e-02, 2.0424e-02, 4.1021e-03, 5.4424e-03, 1.1460e-02,\n",
       "           9.4493e-03, 4.3151e-03, 8.7175e-03, 9.6031e-03, 8.5951e-03, 1.1439e-02,\n",
       "           1.2720e-02],\n",
       "          [1.7507e-02, 4.2045e-03, 1.0837e-01, 7.4446e-02, 2.1161e-02, 1.9225e-02,\n",
       "           1.6854e-02, 5.6337e-03, 1.7064e-02, 1.4446e-02, 2.0542e-02, 2.9354e-02,\n",
       "           2.6347e-02],\n",
       "          [7.1104e-03, 2.0348e-03, 1.6628e-02, 3.2105e-02, 4.0238e-02, 2.9595e-02,\n",
       "           2.4080e-02, 4.9363e-03, 9.3932e-03, 8.3641e-03, 1.5271e-02, 1.1353e-02,\n",
       "           9.4145e-03],\n",
       "          [6.8949e-03, 3.6693e-03, 1.5626e-02, 6.5765e-02, 1.4696e-01, 1.1128e-01,\n",
       "           5.8376e-02, 6.2734e-03, 9.4177e-03, 1.8711e-02, 1.0895e-02, 9.1160e-03,\n",
       "           1.0397e-02],\n",
       "          [4.3452e-03, 2.9986e-03, 7.4859e-03, 2.4783e-02, 9.3963e-02, 1.1714e-01,\n",
       "           7.7841e-02, 1.1079e-02, 1.5946e-02, 3.7541e-03, 1.9271e-02, 2.2282e-02,\n",
       "           8.7548e-03],\n",
       "          [2.5610e-03, 9.6910e-04, 2.8692e-03, 1.3800e-02, 7.4511e-03, 1.0800e-02,\n",
       "           1.0511e-02, 1.4958e-02, 1.5132e-02, 1.1812e-02, 1.3530e-02, 1.5892e-02,\n",
       "           7.8233e-03],\n",
       "          [1.2490e-02, 1.3569e-02, 8.6237e-03, 7.9213e-02, 2.5827e-01, 3.7448e-02,\n",
       "           5.2619e-02, 1.4040e-01, 8.9385e-02, 2.7077e-02, 5.3075e-02, 5.7392e-02,\n",
       "           3.7110e-02],\n",
       "          [6.2965e-03, 1.7730e-02, 4.3749e-03, 1.6377e-02, 9.4457e-02, 2.3992e-02,\n",
       "           2.0904e-02, 4.5783e-02, 3.9150e-02, 9.5804e-03, 2.5236e-02, 2.3780e-02,\n",
       "           1.2867e-02],\n",
       "          [5.2392e-02, 2.0911e-02, 7.7788e-02, 4.0167e-01, 4.8674e-02, 1.7678e-02,\n",
       "           3.8139e-02, 4.7801e-01, 1.9201e-01, 8.7281e-02, 8.2378e-02, 6.6214e-02,\n",
       "           6.2403e-02],\n",
       "          [1.4893e-01, 4.1821e-01, 6.8455e-01, 2.5598e-01, 2.6597e-01, 6.0847e-01,\n",
       "           6.8088e-01, 2.7094e-01, 5.4121e-01, 7.7215e-01, 6.8802e-01, 7.0782e-01,\n",
       "           7.3171e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-1.6289, -0.5985, -0.1416, -0.3728, -4.0680, -2.9950, -3.8845, -6.1824,\n",
       "          -3.1776, -1.8890, -1.7141, -1.1746, -0.1090])}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_sentences_using_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tokens', 'score', 'attention', 'alignment', 'positional_scores'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(translated_sentences_using_generate[0])\n",
    "translated_sentences_using_generate[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_sentences_using_generate_generated_toks = translated_sentences_using_generate[0]['tokens']\n",
    "translated_sentences_using_generate_generated_toks_str_with_bpe = generator_pt.string(translated_sentences_using_generate_generated_toks)\n",
    "translated_sentences_using_generate_generated_toks_str_bpe_removed = generator_pt.remove_bpe(translated_sentences_using_generate_generated_toks_str_with_bpe)\n",
    "fr = generator_pt.detokenize(translated_sentences_using_generate_generated_toks_str_bpe_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour , demain , je vais faire un pique @-@ nique'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_decoded = generator_pt.decode(translated_sentences_using_generate_generated_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour , demain , je vais faire un pique @-@ nique'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': tensor([ 9804,   391,     4, 11548,     4,   471, 13772,   184,    33, 24715,\n",
       "             17, 35429,     2]),\n",
       "  'score': tensor(-0.5770),\n",
       "  'attention': tensor([[4.9452e-01, 2.5984e-02, 1.1782e-01, 1.0228e-01, 2.8326e-02, 8.5267e-02,\n",
       "           8.3771e-03, 5.0618e-03, 3.4623e-03, 8.7738e-03, 8.2156e-04, 5.5009e-04,\n",
       "           3.4776e-02],\n",
       "          [2.1300e-01, 1.4918e-01, 4.2657e-01, 6.8923e-02, 6.1092e-02, 8.3069e-02,\n",
       "           1.0876e-02, 6.8625e-03, 4.8859e-03, 3.6718e-03, 7.6182e-03, 2.4095e-03,\n",
       "           4.1339e-02],\n",
       "          [6.7006e-03, 1.3594e-02, 7.3953e-02, 2.1945e-03, 2.7774e-03, 3.4765e-03,\n",
       "           2.0275e-03, 5.9349e-04, 4.6940e-04, 3.2411e-03, 1.1718e-02, 4.8259e-03,\n",
       "           2.6926e-03],\n",
       "          [1.1468e-02, 5.9789e-03, 6.1731e-02, 1.9828e-03, 1.6616e-03, 1.5582e-03,\n",
       "           1.2446e-03, 1.2807e-03, 8.3491e-04, 1.0579e-03, 4.3197e-03, 2.3071e-03,\n",
       "           2.3031e-03],\n",
       "          [1.5785e-02, 5.5890e-03, 1.4403e-02, 8.2340e-03, 7.9631e-03, 6.1776e-03,\n",
       "           5.5518e-03, 4.1026e-03, 1.4576e-02, 1.5530e-03, 4.5018e-03, 3.2129e-03,\n",
       "           6.7994e-03],\n",
       "          [1.7507e-02, 8.9580e-03, 6.0052e-03, 4.8391e-02, 1.0376e-01, 6.9804e-02,\n",
       "           1.5341e-02, 2.0594e-02, 1.7130e-02, 3.8096e-03, 2.9733e-03, 1.0807e-03,\n",
       "           1.2778e-02],\n",
       "          [7.1104e-03, 1.9473e-03, 1.2723e-03, 2.4874e-02, 3.3783e-02, 2.9038e-02,\n",
       "           3.2005e-02, 6.2606e-03, 4.3090e-03, 1.3220e-03, 9.7481e-04, 2.4712e-04,\n",
       "           4.1332e-03],\n",
       "          [6.8949e-03, 1.9310e-03, 1.0688e-03, 3.9204e-02, 8.0575e-02, 7.0729e-02,\n",
       "           1.2969e-01, 1.9317e-02, 4.7092e-03, 1.8119e-03, 1.0530e-03, 3.3923e-04,\n",
       "           3.8464e-03],\n",
       "          [4.3452e-03, 3.9618e-04, 6.1907e-04, 1.3932e-02, 4.1178e-02, 3.7711e-02,\n",
       "           9.6978e-02, 4.7279e-02, 9.7814e-03, 4.6797e-03, 2.0221e-03, 9.3256e-04,\n",
       "           7.3301e-03],\n",
       "          [2.5610e-03, 3.0437e-04, 4.9595e-04, 7.8539e-03, 2.1054e-02, 1.8220e-02,\n",
       "           7.7381e-03, 2.2172e-02, 2.7235e-02, 8.1564e-03, 3.2817e-03, 1.1809e-03,\n",
       "           6.4816e-03],\n",
       "          [1.2490e-02, 5.8952e-03, 2.5250e-03, 4.1282e-02, 1.6353e-01, 1.5761e-01,\n",
       "           2.7632e-01, 3.8985e-01, 1.5627e-01, 4.8658e-01, 3.8582e-02, 1.5673e-02,\n",
       "           2.8120e-02],\n",
       "          [6.2965e-03, 2.4159e-03, 3.1994e-03, 9.8439e-03, 4.5678e-02, 3.6751e-02,\n",
       "           1.0965e-01, 1.9164e-01, 7.4367e-02, 1.8930e-01, 2.1785e-01, 1.3573e-01,\n",
       "           1.6520e-02],\n",
       "          [5.2392e-02, 2.6608e-02, 5.6384e-03, 4.1731e-01, 6.5586e-02, 1.1789e-01,\n",
       "           2.4526e-02, 5.4493e-02, 1.0737e-01, 2.2131e-02, 2.2896e-02, 3.5656e-03,\n",
       "           1.3558e-01],\n",
       "          [1.4893e-01, 7.5122e-01, 2.8470e-01, 2.1369e-01, 3.4304e-01, 2.8270e-01,\n",
       "           2.7968e-01, 2.3049e-01, 5.7460e-01, 2.6391e-01, 6.8139e-01, 8.2794e-01,\n",
       "           6.9730e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-0.9569, -0.1617, -1.3670, -1.3469, -0.7934, -0.2061, -0.3429, -0.8463,\n",
       "          -0.1570, -0.1277, -0.1216, -0.0506, -1.0229])},\n",
       " {'tokens': tensor([ 9804,   391,    16,   173,     4, 11548,     4,   471, 13772,   184,\n",
       "             33, 24715,    17, 35429,     7,     2]),\n",
       "  'score': tensor(-0.5930),\n",
       "  'attention': tensor([[4.9452e-01, 2.5984e-02, 1.1782e-01, 2.2427e-01, 6.1300e-02, 3.7056e-02,\n",
       "           9.7818e-03, 2.1638e-02, 4.6338e-03, 3.4064e-03, 2.8894e-03, 7.5879e-03,\n",
       "           7.2845e-04, 4.7471e-04, 1.7726e-02, 3.2793e-02],\n",
       "          [2.1300e-01, 1.4918e-01, 4.2657e-01, 2.6486e-01, 1.3356e-01, 2.0533e-02,\n",
       "           1.6008e-02, 1.7002e-02, 5.7308e-03, 4.7128e-03, 4.0647e-03, 3.0632e-03,\n",
       "           6.6408e-03, 2.0188e-03, 2.0701e-02, 2.1882e-02],\n",
       "          [6.7006e-03, 1.3594e-02, 7.3953e-02, 2.1870e-02, 7.1546e-03, 8.4012e-04,\n",
       "           1.0892e-03, 1.1244e-03, 1.1165e-03, 4.0900e-04, 4.0220e-04, 2.6992e-03,\n",
       "           1.0871e-02, 4.2000e-03, 1.4843e-03, 2.3753e-03],\n",
       "          [1.1468e-02, 5.9789e-03, 6.1731e-02, 4.1392e-02, 7.2530e-03, 5.8079e-04,\n",
       "           5.7874e-04, 4.3766e-04, 6.4070e-04, 7.2260e-04, 6.6873e-04, 8.2884e-04,\n",
       "           3.7195e-03, 1.9574e-03, 1.2795e-03, 1.4458e-03],\n",
       "          [1.5785e-02, 5.5890e-03, 1.4403e-02, 1.7385e-02, 2.6247e-02, 5.3051e-03,\n",
       "           4.9850e-03, 4.1419e-03, 3.9486e-03, 3.2141e-03, 1.4274e-02, 1.4337e-03,\n",
       "           4.0708e-03, 3.2441e-03, 5.0423e-03, 1.0905e-02],\n",
       "          [1.7507e-02, 8.9580e-03, 6.0052e-03, 9.1000e-03, 6.7429e-02, 6.6657e-02,\n",
       "           9.6376e-02, 8.0693e-02, 1.4786e-02, 2.0008e-02, 1.8349e-02, 3.8394e-03,\n",
       "           2.7070e-03, 1.0727e-03, 1.2737e-02, 1.5511e-02],\n",
       "          [7.1104e-03, 1.9473e-03, 1.2723e-03, 9.8049e-04, 1.4408e-02, 3.3217e-02,\n",
       "           3.6739e-02, 3.4006e-02, 3.1072e-02, 6.5388e-03, 4.3547e-03, 1.3773e-03,\n",
       "           9.3635e-04, 2.4880e-04, 4.1701e-03, 4.6471e-03],\n",
       "          [6.8949e-03, 1.9310e-03, 1.0688e-03, 1.3952e-03, 1.0235e-02, 5.4362e-02,\n",
       "           9.9740e-02, 8.8957e-02, 1.3102e-01, 2.1106e-02, 4.8345e-03, 1.8795e-03,\n",
       "           1.0516e-03, 3.4511e-04, 4.1233e-03, 4.5326e-03],\n",
       "          [4.3452e-03, 3.9618e-04, 6.1907e-04, 8.3980e-04, 5.8609e-03, 2.1920e-02,\n",
       "           4.9901e-02, 5.2771e-02, 9.8675e-02, 4.8289e-02, 9.9549e-03, 4.8066e-03,\n",
       "           1.9919e-03, 9.1963e-04, 8.3761e-03, 2.9821e-03],\n",
       "          [2.5610e-03, 3.0437e-04, 4.9595e-04, 2.3865e-03, 2.4017e-03, 1.1626e-02,\n",
       "           2.6873e-02, 2.4521e-02, 8.8594e-03, 2.2016e-02, 2.7488e-02, 8.8608e-03,\n",
       "           3.1331e-03, 1.1509e-03, 8.1033e-03, 3.1262e-03],\n",
       "          [1.2490e-02, 5.8952e-03, 2.5250e-03, 3.2356e-03, 1.2262e-02, 7.4054e-02,\n",
       "           1.9337e-01, 1.9971e-01, 2.8362e-01, 3.8402e-01, 1.6022e-01, 4.8539e-01,\n",
       "           3.9346e-02, 1.5509e-02, 3.3212e-02, 9.6052e-03],\n",
       "          [6.2965e-03, 2.4159e-03, 3.1994e-03, 2.5585e-03, 3.6606e-03, 1.4835e-02,\n",
       "           5.9049e-02, 4.7501e-02, 1.1893e-01, 1.9298e-01, 7.6351e-02, 1.8848e-01,\n",
       "           2.2724e-01, 1.3566e-01, 1.9629e-02, 4.2680e-03],\n",
       "          [5.2392e-02, 2.6608e-02, 5.6384e-03, 3.7852e-03, 8.4266e-02, 4.4486e-01,\n",
       "           7.0072e-02, 1.1362e-01, 2.7599e-02, 6.0244e-02, 1.0866e-01, 2.4138e-02,\n",
       "           2.4043e-02, 3.5086e-03, 1.6752e-01, 3.9772e-02],\n",
       "          [1.4893e-01, 7.5122e-01, 2.8470e-01, 4.0594e-01, 5.6396e-01, 2.1416e-01,\n",
       "           3.3543e-01, 3.1388e-01, 2.6936e-01, 2.3234e-01, 5.6749e-01, 2.6561e-01,\n",
       "           6.7352e-01, 8.2969e-01, 6.9589e-01, 8.4615e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-0.9569, -0.1617, -2.1894, -0.2832, -0.5154, -1.5030, -1.0885, -0.1961,\n",
       "          -0.3272, -0.8740, -0.1678, -0.1266, -0.1252, -0.0528, -0.8152, -0.1055])},\n",
       " {'tokens': tensor([  255,  7243, 33597,   342,     4, 11548,   471, 13772, 24715,    17,\n",
       "           2511,  6062,     2]),\n",
       "  'score': tensor(-0.7311),\n",
       "  'attention': tensor([[4.9452e-01, 1.3585e-01, 4.4123e-02, 1.2497e-02, 2.9693e-02, 1.6742e-02,\n",
       "           6.4132e-03, 3.2266e-03, 2.4082e-03, 6.4964e-04, 5.5629e-04, 2.3096e-03,\n",
       "           1.9518e-02],\n",
       "          [2.1300e-01, 1.0203e-01, 3.4556e-01, 1.8764e-02, 3.6897e-02, 7.9515e-03,\n",
       "           8.3280e-03, 3.2478e-03, 2.6372e-03, 4.4293e-03, 1.8642e-03, 2.1742e-03,\n",
       "           1.6817e-02],\n",
       "          [6.7006e-03, 1.4069e-02, 4.7352e-02, 9.6709e-03, 3.3410e-03, 4.1474e-04,\n",
       "           7.5571e-04, 8.4526e-04, 2.8618e-04, 8.3541e-03, 3.1534e-03, 4.0001e-03,\n",
       "           1.8327e-03],\n",
       "          [1.1468e-02, 9.0962e-03, 4.7761e-02, 3.6612e-02, 7.4676e-03, 2.5475e-04,\n",
       "           3.9529e-04, 4.4294e-04, 5.3031e-04, 1.9742e-03, 1.4852e-03, 4.3964e-03,\n",
       "           2.0791e-03],\n",
       "          [1.5785e-02, 1.1480e-02, 1.1597e-02, 4.6172e-02, 3.1943e-02, 3.4167e-03,\n",
       "           4.0220e-03, 3.1314e-03, 2.5396e-03, 3.8614e-03, 3.0320e-03, 3.0717e-03,\n",
       "           7.1614e-03],\n",
       "          [1.7507e-02, 4.9424e-03, 3.4959e-03, 4.9837e-03, 9.4726e-02, 7.7688e-02,\n",
       "           1.0192e-01, 1.6006e-02, 1.9243e-02, 2.9924e-03, 1.7322e-03, 6.0436e-03,\n",
       "           1.5599e-02],\n",
       "          [7.1104e-03, 2.1022e-03, 1.2851e-03, 1.7082e-03, 1.3429e-02, 3.2266e-02,\n",
       "           3.2165e-02, 3.1169e-02, 5.7192e-03, 6.8131e-04, 2.8157e-04, 1.1455e-03,\n",
       "           5.4016e-03],\n",
       "          [6.8949e-03, 3.2747e-03, 2.2398e-03, 8.8357e-04, 9.9391e-03, 6.3334e-02,\n",
       "           8.6630e-02, 1.4277e-01, 2.0394e-02, 1.0376e-03, 4.7074e-04, 1.6685e-03,\n",
       "           4.9515e-03],\n",
       "          [4.3452e-03, 8.7168e-04, 2.1475e-03, 1.0176e-03, 8.2549e-03, 3.1301e-02,\n",
       "           5.0311e-02, 9.9352e-02, 4.5420e-02, 1.9549e-03, 1.3160e-03, 2.3691e-03,\n",
       "           8.2044e-03],\n",
       "          [2.5610e-03, 1.9285e-03, 5.5399e-04, 1.1661e-03, 2.9941e-03, 1.6388e-02,\n",
       "           2.8564e-02, 9.3760e-03, 2.4587e-02, 2.4072e-03, 1.2974e-03, 2.3617e-03,\n",
       "           1.0838e-02],\n",
       "          [1.2490e-02, 1.9890e-03, 6.9380e-03, 1.1110e-03, 8.3135e-03, 1.5091e-01,\n",
       "           2.1451e-01, 2.9324e-01, 4.0789e-01, 2.5622e-02, 8.9431e-03, 7.2472e-03,\n",
       "           1.9608e-02],\n",
       "          [6.2965e-03, 1.3842e-03, 1.6471e-02, 3.5582e-03, 4.5438e-03, 3.0249e-02,\n",
       "           6.6143e-02, 1.2819e-01, 2.0219e-01, 1.4877e-01, 9.0957e-02, 3.7003e-02,\n",
       "           1.4134e-02],\n",
       "          [5.2392e-02, 3.5404e-03, 1.4162e-02, 5.5330e-03, 1.1304e-01, 3.5947e-01,\n",
       "           4.7788e-02, 2.1750e-02, 4.1887e-02, 1.7978e-02, 5.3857e-03, 1.4980e-02,\n",
       "           6.0272e-02],\n",
       "          [1.4893e-01, 7.0745e-01, 4.5632e-01, 8.5632e-01, 6.3542e-01, 2.0962e-01,\n",
       "           3.5205e-01, 2.4726e-01, 2.2427e-01, 7.7928e-01, 8.7953e-01, 9.1123e-01,\n",
       "           8.1358e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-2.5025, -0.0329, -1.3654, -0.0914, -0.1681, -1.8778, -0.7552, -0.2605,\n",
       "          -1.3514, -0.1690, -0.2029, -0.0859, -0.6414])},\n",
       " {'tokens': tensor([  330,  9599,     4,   471, 13772,   613,  1766,    16,  2100, 24715,\n",
       "             17,  2511,    30, 11548,     7,     2]),\n",
       "  'score': tensor(-1.4728),\n",
       "  'attention': tensor([[4.9452e-01, 3.7554e-01, 2.9943e-01, 2.1153e-01, 3.7620e-02, 1.3655e-02,\n",
       "           1.0591e-02, 9.2783e-03, 1.1494e-02, 2.9785e-02, 1.2891e-03, 5.1925e-04,\n",
       "           2.6793e-03, 1.6594e-02, 5.3180e-02, 6.9167e-02],\n",
       "          [2.1300e-01, 2.0713e-01, 1.3619e-01, 1.0523e-01, 3.6103e-02, 1.3860e-02,\n",
       "           1.2281e-02, 9.4122e-03, 8.9538e-03, 6.8628e-03, 1.0576e-02, 2.4426e-03,\n",
       "           2.7903e-03, 1.0862e-02, 7.2372e-02, 4.4577e-02],\n",
       "          [6.7006e-03, 1.1097e-02, 4.6503e-03, 3.3071e-03, 4.1161e-03, 6.8116e-04,\n",
       "           2.5890e-03, 2.5849e-04, 6.2511e-04, 2.5306e-03, 1.6034e-02, 5.9949e-03,\n",
       "           3.8503e-03, 4.3977e-04, 4.4042e-03, 4.9723e-03],\n",
       "          [1.1468e-02, 1.3790e-02, 1.6560e-02, 3.7970e-03, 4.1354e-03, 2.2762e-03,\n",
       "           1.2842e-03, 7.5745e-04, 1.0691e-03, 1.3514e-03, 4.8707e-03, 2.1308e-03,\n",
       "           5.6880e-03, 5.8239e-04, 3.8652e-03, 3.6958e-03],\n",
       "          [1.5785e-02, 1.0376e-02, 2.0598e-02, 1.4755e-02, 1.4317e-02, 8.9064e-03,\n",
       "           7.5483e-03, 5.9920e-03, 5.1063e-03, 2.9464e-03, 5.1026e-03, 2.9868e-03,\n",
       "           4.6222e-03, 4.4139e-03, 1.1597e-02, 1.4984e-02],\n",
       "          [1.7507e-02, 9.5585e-03, 6.1962e-02, 7.6546e-02, 2.5511e-02, 2.6947e-02,\n",
       "           1.3270e-02, 1.1245e-02, 2.6872e-02, 7.1430e-03, 3.0213e-03, 9.7909e-04,\n",
       "           5.7564e-03, 1.3030e-02, 1.1898e-02, 1.4489e-02],\n",
       "          [7.1104e-03, 1.4554e-03, 1.0230e-02, 3.9487e-02, 4.5566e-02, 8.7089e-03,\n",
       "           1.3913e-02, 4.0823e-03, 4.7661e-03, 5.3995e-03, 1.2087e-03, 2.1235e-04,\n",
       "           1.1483e-03, 5.3801e-03, 5.1523e-03, 4.4333e-03],\n",
       "          [6.8949e-03, 1.6040e-03, 8.7721e-03, 6.0788e-02, 1.2222e-01, 2.4009e-02,\n",
       "           1.7281e-02, 4.1051e-03, 9.5227e-03, 6.7331e-03, 1.1666e-03, 2.2215e-04,\n",
       "           7.8600e-04, 5.9918e-03, 4.1103e-03, 3.8829e-03],\n",
       "          [4.3452e-03, 1.3551e-03, 4.3735e-03, 3.0054e-02, 8.8164e-02, 4.6668e-02,\n",
       "           8.2891e-02, 1.0335e-02, 1.8871e-02, 1.3138e-02, 2.4523e-03, 7.1571e-04,\n",
       "           1.2279e-03, 9.2084e-03, 8.0291e-03, 2.5238e-03],\n",
       "          [2.5610e-03, 1.9818e-03, 4.5965e-03, 1.4230e-02, 6.8634e-03, 1.9224e-02,\n",
       "           1.6402e-02, 2.4714e-02, 5.4510e-02, 1.5025e-02, 3.5624e-03, 1.0336e-03,\n",
       "           1.7147e-03, 7.2362e-03, 5.2394e-03, 2.3470e-03],\n",
       "          [1.2490e-02, 5.8837e-03, 1.0906e-02, 6.3146e-02, 2.3591e-01, 3.7683e-01,\n",
       "           1.5395e-01, 1.4485e-01, 1.9095e-01, 4.1684e-01, 5.1315e-02, 1.0143e-02,\n",
       "           5.2155e-03, 4.3009e-02, 1.9825e-02, 8.7595e-03],\n",
       "          [6.2965e-03, 6.3901e-03, 7.5919e-03, 2.0596e-02, 8.4834e-02, 1.6582e-01,\n",
       "           7.0561e-02, 7.0120e-02, 1.4321e-01, 2.3240e-01, 2.2625e-01, 1.1795e-01,\n",
       "           2.9042e-02, 2.3409e-02, 1.0335e-02, 4.1289e-03],\n",
       "          [5.2392e-02, 6.9642e-03, 6.7493e-02, 1.3669e-01, 3.8218e-02, 1.1355e-01,\n",
       "           2.5946e-02, 3.7382e-01, 6.9286e-02, 1.5444e-02, 2.2190e-02, 2.7216e-03,\n",
       "           1.2591e-02, 5.1361e-01, 3.3335e-02, 2.5348e-02],\n",
       "          [1.4893e-01, 3.4687e-01, 3.4665e-01, 2.1985e-01, 2.5642e-01, 1.7886e-01,\n",
       "           5.7149e-01, 3.3104e-01, 4.5476e-01, 2.4440e-01, 6.5096e-01, 8.5195e-01,\n",
       "           9.2289e-01, 3.4623e-01, 7.5666e-01, 7.9669e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-5.1777, -3.7706, -0.2636, -0.4439, -0.6683, -2.7314, -0.2357, -0.3727,\n",
       "          -3.5801, -0.2437, -0.1322, -4.0542, -0.3719, -0.7036, -0.7097, -0.1054])},\n",
       " {'tokens': tensor([15671,  9255,     4,   471,  3740,   109, 13772, 19481,    11, 10680,\n",
       "           9255,     7,     2]),\n",
       "  'score': tensor(-2.1489),\n",
       "  'attention': tensor([[4.9452e-01, 5.6259e-02, 1.9477e-02, 1.9461e-02, 7.3392e-03, 6.6423e-03,\n",
       "           4.6061e-03, 1.0623e-02, 1.6758e-02, 1.7165e-02, 1.4411e-02, 1.6709e-02,\n",
       "           4.6999e-02],\n",
       "          [2.1300e-01, 3.5108e-01, 2.7485e-02, 1.1486e-02, 8.1609e-03, 3.8599e-03,\n",
       "           4.1037e-03, 6.4435e-03, 4.2753e-02, 1.7727e-02, 4.4695e-02, 2.6083e-02,\n",
       "           2.8783e-02],\n",
       "          [6.7006e-03, 5.5886e-02, 2.5912e-03, 5.1184e-04, 1.1061e-03, 1.3246e-03,\n",
       "           9.0015e-04, 2.2280e-04, 1.7765e-03, 1.3839e-03, 2.4601e-03, 1.4648e-03,\n",
       "           3.0954e-03],\n",
       "          [1.1468e-02, 4.1106e-02, 3.6995e-03, 2.9827e-04, 8.1164e-04, 1.0841e-03,\n",
       "           7.3864e-04, 3.8588e-04, 1.2826e-03, 9.4682e-04, 1.6214e-03, 1.0989e-03,\n",
       "           1.5759e-03],\n",
       "          [1.5785e-02, 1.1369e-02, 2.0424e-02, 4.1021e-03, 5.4424e-03, 1.1460e-02,\n",
       "           9.4493e-03, 4.3151e-03, 8.7175e-03, 9.6031e-03, 8.5951e-03, 1.1439e-02,\n",
       "           1.2720e-02],\n",
       "          [1.7507e-02, 4.2045e-03, 1.0837e-01, 7.4446e-02, 2.1161e-02, 1.9225e-02,\n",
       "           1.6854e-02, 5.6337e-03, 1.7064e-02, 1.4446e-02, 2.0542e-02, 2.9354e-02,\n",
       "           2.6347e-02],\n",
       "          [7.1104e-03, 2.0348e-03, 1.6628e-02, 3.2105e-02, 4.0238e-02, 2.9595e-02,\n",
       "           2.4080e-02, 4.9363e-03, 9.3932e-03, 8.3641e-03, 1.5271e-02, 1.1353e-02,\n",
       "           9.4145e-03],\n",
       "          [6.8949e-03, 3.6693e-03, 1.5626e-02, 6.5765e-02, 1.4696e-01, 1.1128e-01,\n",
       "           5.8376e-02, 6.2734e-03, 9.4177e-03, 1.8711e-02, 1.0895e-02, 9.1160e-03,\n",
       "           1.0397e-02],\n",
       "          [4.3452e-03, 2.9986e-03, 7.4859e-03, 2.4783e-02, 9.3963e-02, 1.1714e-01,\n",
       "           7.7841e-02, 1.1079e-02, 1.5946e-02, 3.7541e-03, 1.9271e-02, 2.2282e-02,\n",
       "           8.7548e-03],\n",
       "          [2.5610e-03, 9.6910e-04, 2.8692e-03, 1.3800e-02, 7.4511e-03, 1.0800e-02,\n",
       "           1.0511e-02, 1.4958e-02, 1.5132e-02, 1.1812e-02, 1.3530e-02, 1.5892e-02,\n",
       "           7.8233e-03],\n",
       "          [1.2490e-02, 1.3569e-02, 8.6237e-03, 7.9213e-02, 2.5827e-01, 3.7448e-02,\n",
       "           5.2619e-02, 1.4040e-01, 8.9385e-02, 2.7077e-02, 5.3075e-02, 5.7392e-02,\n",
       "           3.7110e-02],\n",
       "          [6.2965e-03, 1.7730e-02, 4.3749e-03, 1.6377e-02, 9.4457e-02, 2.3992e-02,\n",
       "           2.0904e-02, 4.5783e-02, 3.9150e-02, 9.5804e-03, 2.5236e-02, 2.3780e-02,\n",
       "           1.2867e-02],\n",
       "          [5.2392e-02, 2.0911e-02, 7.7788e-02, 4.0167e-01, 4.8674e-02, 1.7678e-02,\n",
       "           3.8139e-02, 4.7801e-01, 1.9201e-01, 8.7281e-02, 8.2378e-02, 6.6214e-02,\n",
       "           6.2403e-02],\n",
       "          [1.4893e-01, 4.1821e-01, 6.8455e-01, 2.5598e-01, 2.6597e-01, 6.0847e-01,\n",
       "           6.8088e-01, 2.7094e-01, 5.4121e-01, 7.7215e-01, 6.8802e-01, 7.0782e-01,\n",
       "           7.3171e-01]]),\n",
       "  'alignment': tensor([]),\n",
       "  'positional_scores': tensor([-1.6289, -0.5985, -0.1416, -0.3728, -4.0680, -2.9950, -3.8845, -6.1824,\n",
       "          -3.1776, -1.8890, -1.7141, -1.1746, -0.1090])}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_sentences_using_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/paperspace/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-04-16 17:36:35 | INFO | fairseq.file_utils | loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 from cache at /home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "2024-04-16 17:36:38 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2024-04-16 17:36:38 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2024-04-16 17:36:43 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0253:58342', 'distributed_port': 58342, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 5120, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5120, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', seed=2, data='/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', source_lang='en', target_lang='fr', max_source_positions=1024, max_target_positions=1024, skip_invalid_size_inputs_valid_test=False, max_tokens=5120, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, sample_without_replacement=0, distributed_world_size=128, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0253:58342', distributed_port=58342, device_id=0, arch='transformer_vaswani_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=80000, clip_norm=0.0, sentence_avg=False, update_freq=[1.0], fp16=True, optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', restore_file='checkpoint_last.pt', save_interval=1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, dropout=0.1, attention_dropout=0.0, relu_dropout=0.0, encoder_normalize_before=False, encoder_learned_pos=False, decoder_learned_pos=False, decoder_normalize_before=False, share_decoder_input_output_embed=True, share_all_embeddings=True, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_attention_heads=16, tokenizer='moses', bpe='subword_nmt', bpe_codes='/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', task='translation', stop_min_lr=1e-09, _name='transformer_vaswani_wmt_en_de_big', encoder_embed_path=None, decoder_embed_path=None, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', 'bpe_separator': '@@'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'fr', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Dictionary not found in the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     dictionary \u001b[38;5;241m=\u001b[39m generator_pt\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdictionary\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictionary not found in the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use this dictionary to get the padding index\u001b[39;00m\n\u001b[1;32m     19\u001b[0m pad_idx \u001b[38;5;241m=\u001b[39m dictionary\u001b[38;5;241m.\u001b[39mpad()\n",
      "\u001b[0;31mException\u001b[0m: Dictionary not found in the model"
     ]
    }
   ],
   "source": [
    "# Assuming 'en2fr' is your FairSeq model loaded and ready\n",
    "import torch\n",
    "from fairseq.data.data_utils import collate_tokens\n",
    "generator_pt_hub = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n",
    "\n",
    "# Prepare your input text\n",
    "text = \"Hello world!\"\n",
    "tokens = generator_pt_hub.tokenize(text)\n",
    "bpe_tokens = generator_pt_hub.apply_bpe(tokens)\n",
    "binarized_tokens = generator_pt_hub.binarize(bpe_tokens)\n",
    "\n",
    "# Assuming generator_pt is your GeneratorHubInterface loaded model\n",
    "if hasattr(generator_pt.models[0], 'dictionary'):\n",
    "    dictionary = generator_pt.models[0].dictionary\n",
    "else:\n",
    "    raise Exception(\"Dictionary not found in the model\")\n",
    "\n",
    "# Use this dictionary to get the padding index\n",
    "pad_idx = dictionary.pad()\n",
    "\n",
    "# Now you can collate tokens\n",
    "batch = collate_tokens([binarized_tokens], pad_idx=pad_idx)\n",
    "\n",
    "\n",
    "generator_pt.models[0].eval()\n",
    "\n",
    "# If you have a simple forward method available\n",
    "with torch.no_grad():\n",
    "    logits = generator_pt.models[0](batch['net_input']['src_tokens'], batch['net_input']['src_lengths'])\n",
    "    logits = logits[0]  # assuming the logits are the first return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator_pt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/zipball/main\" to /home/paperspace/.cache/torch/hub/main.zip\n",
      "2024-04-16 16:54:59 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 not found in cache, downloading to /tmp/tmp_tt6rcr9\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2316140317/2316140317 [00:59<00:00, 38829048.86B/s]\n",
      "2024-04-16 16:55:59 | INFO | fairseq.file_utils | copying /tmp/tmp_tt6rcr9 to cache at /home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "2024-04-16 16:56:02 | INFO | fairseq.file_utils | creating metadata file for /home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "2024-04-16 16:56:02 | INFO | fairseq.file_utils | removing temp file /tmp/tmp_tt6rcr9\n",
      "2024-04-16 16:56:02 | INFO | fairseq.file_utils | loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 from cache at /home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "2024-04-16 16:56:02 | INFO | fairseq.file_utils | extracting archive file /home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae to temp dir /tmp/tmp3t8_n3cb\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:425: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/hydra/compose.py:56: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "/home/paperspace/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/fairseq/models/fairseq_model.py:267: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  x = hub_utils.from_pretrained(\n",
      "2024-04-16 17:05:20 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2024-04-16 17:05:20 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2024-04-16 17:05:25 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0253:58342', 'distributed_port': 58342, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 5120, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5120, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', seed=2, data='/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', source_lang='en', target_lang='fr', max_source_positions=1024, max_target_positions=1024, skip_invalid_size_inputs_valid_test=False, max_tokens=5120, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, sample_without_replacement=0, distributed_world_size=128, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0253:58342', distributed_port=58342, device_id=0, arch='transformer_vaswani_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=80000, clip_norm=0.0, sentence_avg=False, update_freq=[1.0], fp16=True, optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', restore_file='checkpoint_last.pt', save_interval=1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, dropout=0.1, attention_dropout=0.0, relu_dropout=0.0, encoder_normalize_before=False, encoder_learned_pos=False, decoder_learned_pos=False, decoder_normalize_before=False, share_decoder_input_output_embed=True, share_all_embeddings=True, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_attention_heads=16, tokenizer='moses', bpe='subword_nmt', bpe_codes='/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', task='translation', stop_min_lr=1e-09, _name='transformer_vaswani_wmt_en_de_big', encoder_embed_path=None, decoder_embed_path=None, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/home/paperspace/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', 'bpe_separator': '@@'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'fr', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load an En-Fr Transformer model trained on WMT'14 data :\n",
    "en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n",
    "\n",
    "# Use the GPU (optional):\n",
    "en2fr.cuda()\n",
    "\n",
    "# Translate with beam search:\n",
    "fr = en2fr.translate('Hello world!', beam=5)\n",
    "assert fr == 'Bonjour √† tous !'\n",
    "\n",
    "# Manually tokenize:\n",
    "en_toks = en2fr.tokenize('Hello world!')\n",
    "assert en_toks == 'Hello world !'\n",
    "\n",
    "# Manually apply BPE:\n",
    "en_bpe = en2fr.apply_bpe(en_toks)\n",
    "assert en_bpe == 'H@@ ello world !'\n",
    "\n",
    "# Manually binarize:\n",
    "en_bin = en2fr.binarize(en_bpe)\n",
    "assert en_bin.tolist() == [329, 14044, 682, 812, 2]\n",
    "\n",
    "# Generate five translations with top-k sampling:\n",
    "fr_bin = en2fr.generate(en_bin, beam=5, sampling=True, sampling_topk=20)\n",
    "assert len(fr_bin) == 5\n",
    "\n",
    "# Convert one of the samples to a string and detokenize\n",
    "fr_sample = fr_bin[0]['tokens']\n",
    "fr_bpe = en2fr.string(fr_sample)\n",
    "fr_toks = en2fr.remove_bpe(fr_bpe)\n",
    "fr = en2fr.detokenize(fr_toks)\n",
    "assert fr == en2fr.decode(fr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bon matin , je vais faire un pique @-@ nique demain .', 'Bon apr√®s @-@ midi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44512, 1024])\n",
      "torch.Size([44512, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder_embeddings = generator_pt.models[0].encoder.embed_tokens\n",
    "decoder_embeddings = generator_pt.models[0].decoder.embed_tokens\n",
    "\n",
    "# Example: print the size of the embedding layer\n",
    "print(encoder_embeddings.weight.size())\n",
    "print(decoder_embeddings.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoderLayerBase(\n",
      "  (dropout_module): FairseqDropout()\n",
      "  (self_attn): MultiheadAttention(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (activation_dropout_module): FairseqDropout()\n",
      "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): MultiheadAttention(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Accessing all decoder layers\n",
    "decoder_layers = generator_pt.models[0].decoder.layers\n",
    "\n",
    "# Access a specific layer, e.g., the first layer\n",
    "first_decoder_layer = generator_pt.models[0].decoder.layers[0]\n",
    "\n",
    "# Example: print the model of the first decoder layer\n",
    "print(first_decoder_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiheadAttention(\n",
      "  (dropout_module): FairseqDropout()\n",
      "  (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Access components of the first decoder layer\n",
    "self_attn = first_decoder_layer.self_attn\n",
    "feed_forward = first_decoder_layer.fc1 # This accesses the first fully connected layer in the feedforward network\n",
    "\n",
    "# Example: print the self-attention module\n",
    "print(self_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__dataclass', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_get_backward_hooks', '_get_name', '_is_full_backward_hook', '_is_generation_fast', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_args', 'add_module', 'apply', 'args', 'bfloat16', 'buffers', 'build_decoder', 'build_embedding', 'build_encoder', 'build_model', 'cfg', 'children', 'cpu', 'cuda', 'decoder', 'double', 'dump_patches', 'encoder', 'eval', 'extra_repr', 'extract_features', 'float', 'forward', 'forward_decoder', 'from_pretrained', 'get_buffer', 'get_extra_state', 'get_normalized_probs', 'get_normalized_probs_scriptable', 'get_parameter', 'get_submodule', 'get_targets', 'half', 'hub_models', 'ipu', 'load_state_dict', 'make_generation_fast_', 'max_decoder_positions', 'max_positions', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'output_layer', 'parameters', 'prepare_for_inference_', 'prepare_for_onnx_export_', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'requires_grad_', 'set_extra_state', 'set_num_updates', 'share_memory', 'state_dict', 'supports_align_args', 'to', 'to_empty', 'train', 'train', 'training', 'type', 'upgrade_state_dict', 'upgrade_state_dict_named', 'xpu', 'zero_grad']\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_get_backward_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_encoder_out', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'build_encoder_layer', 'cfg', 'children', 'cpu', 'cuda', 'dictionary', 'double', 'dropout_module', 'dump_patches', 'embed_positions', 'embed_scale', 'embed_tokens', 'encoder_layerdrop', 'eval', 'extra_repr', 'float', 'forward', 'forward_embedding', 'forward_non_torchscript', 'forward_scriptable', 'forward_torchscript', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'layer_norm', 'layernorm_embedding', 'layers', 'load_state_dict', 'max_positions', 'max_source_positions', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'normalize', 'num_layers', 'padding_idx', 'parameters', 'quant_noise', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'reorder_encoder_out', 'requires_grad_', 'return_fc', 'set_extra_state', 'set_num_updates', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'upgrade_state_dict_named', 'version', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(generator_pt.models[0]))\n",
    "print(dir(generator_pt.models[0].encoder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints_path_dict_format = '/home/paperspace/google_drive_v1/Research_Thesis/2024/git_repo/best_checkpoint_dict_format_2.pt'\n",
    "checkpoints_path_dict_format = '/home/paperspace/best_checkpoint_dict_format_2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoints_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/torch/serialization.py:705\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    707\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/preprocess_bert_udem/lib/python3.10/site-packages/torch/serialization.py:242\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_zipfile_reader, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "checkpoint_dict = torch.load(checkpoints_path_dict_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path_reg_format = '/home/paperspace/google_drive_v1/Research_Thesis/2024/git_repo/best_discriminator_at_2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint_reg = torch.load(checkpoints_path_reg_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = discriminator_cnn.state_dict()\n",
    "model = torch.load(checkpoints_path)\n",
    "pretrained_dict = model.state_dict()\n",
    "print(\"pretrained_dict type: \", type(pretrained_dict))\n",
    "print(\"model : \",model)\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k,\n",
    "                    v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict)\n",
    "# 3. load the new state dict\n",
    "discriminator_cnn.load_state_dict(model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
