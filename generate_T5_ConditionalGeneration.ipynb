{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\"translate English to German: The house is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"Das Haus ist wunderbar.\", return_tensors=\"pt\").input_ids\n",
    "\n",
    "# the forward function automatically creates the correct decoder_input_ids\n",
    "loss = model(input_ids=input_ids, labels=labels).loss\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.42k/1.42k [00:00<00:00, 5.86MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 301M/301M [00:01<00:00, 299MB/s] \n",
      "generation_config.json: 100%|██████████| 293/293 [00:00<00:00, 1.47MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 42.0/42.0 [00:00<00:00, 234kB/s]\n",
      "source.spm: 100%|██████████| 802k/802k [00:00<00:00, 21.6MB/s]\n",
      "target.spm: 100%|██████████| 778k/778k [00:00<00:00, 43.9MB/s]\n",
      "vocab.json: 100%|██████████| 1.34M/1.34M [00:00<00:00, 2.77MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Where's the bus stop?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, MarianMTModel\n",
    "\n",
    "src = \"en\"  # source language\n",
    "trg = \"fr\"  # target language\n",
    "\n",
    "model_name = f\"Helsinki-NLP/opus-mt-{src}-{trg}\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# sample_text = \"où est l'arrêt de bus ?\"\n",
    "sample_text = \"where is the bus stop?\"\n",
    "batch = tokenizer([sample_text], return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(**batch)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocess_bert_udem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
